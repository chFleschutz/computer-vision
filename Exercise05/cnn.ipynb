{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 600\n",
      "Number of testing batches: 100\n"
     ]
    }
   ],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.RandomCrop(size=(28, 28), padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # mean and std of MNIST dataset\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # mean and std of MNIST dataset\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./../data', train=True, transform=train_transforms, download=True)\n",
    "test_dataset = datasets.MNIST(root='./../data', train=False, transform=test_transforms, download=True)\n",
    "\n",
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f'Number of training batches: {len(train_loader)}')\n",
    "print(f'Number of testing batches: {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, epochs, scheduler=None):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate training accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f'Epoch {epoch + 1}/{epochs}, Step {i + 1}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        # Epoch summary\n",
    "        train_accuracy = correct / total * 100\n",
    "        test_accuracy = test(model)\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(train_loader):.4f}, Training Accuracy: {train_accuracy:.2f}%, Validation Accuracy: {test_accuracy:.2f}%\\n')\n",
    "\n",
    "\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total * 100\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_summary(model):\n",
    "    def layer_summary(layer):\n",
    "        output_shape = None\n",
    "        if hasattr(layer, 'out_channels'):\n",
    "            output_shape = (layer.out_channels, \"H_out\", \"W_out\")\n",
    "        elif hasattr(layer, 'out_features'):\n",
    "            output_shape = (layer.out_features)\n",
    "        elif isinstance(layer, torch.nn.modules.pooling._MaxPoolNd):\n",
    "            output_shape = (layer.kernel_size, \"H_out\", \"W_out\")\n",
    "\n",
    "        num_params = sum(p.numel() for p in layer.parameters() if p.requires_grad)\n",
    "        return output_shape, num_params\n",
    "\n",
    "    model_name = model.__class__.__name__\n",
    "    print(f\"'{model_name}' Model Summary:\")\n",
    "\n",
    "    print(\"=\"*75)\n",
    "    print(f\"{'Layer':<30} {'Output Shape':<30} {'Param #':<15}\")\n",
    "    print(\"=\"*75)\n",
    "    \n",
    "    for name, layer in model.named_children():\n",
    "        output_shape, num_params = layer_summary(layer)\n",
    "        print(f\"{name:<30} {str(output_shape):<30} {num_params:<15}\")\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    print(\"=\"*75)\n",
    "    print(f\"Total params:          {total_params}\")\n",
    "    print(f\"Trainable params:      {trainable_params}\")\n",
    "    print(f\"Non-trainable params:  {total_params - trainable_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'AccuracyOptimCNN' Model Summary:\n",
      "===========================================================================\n",
      "Layer                          Output Shape                   Param #        \n",
      "===========================================================================\n",
      "conv1                          (32, 'H_out', 'W_out')         320            \n",
      "conv2                          (64, 'H_out', 'W_out')         18496          \n",
      "conv3                          (32, 'H_out', 'W_out')         18464          \n",
      "conv4                          (64, 'H_out', 'W_out')         18496          \n",
      "bn1                            None                           64             \n",
      "bn2                            None                           128            \n",
      "bn3                            None                           64             \n",
      "bn4                            None                           128            \n",
      "pool                           (2, 'H_out', 'W_out')          0              \n",
      "dropout1                       None                           0              \n",
      "fc1                            64                             200768         \n",
      "dropout2                       None                           0              \n",
      "fc2                            10                             650            \n",
      "===========================================================================\n",
      "Total params:          257578\n",
      "Trainable params:      257578\n",
      "Non-trainable params:  0\n"
     ]
    }
   ],
   "source": [
    "class AccuracyOptimCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AccuracyOptimCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 64)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.conv1(x)))\n",
    "        x = torch.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.view(-1, 64 * 7 * 7) # Flatten the tensor\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "ao_model = AccuracyOptimCNN().to(device)\n",
    "ao_criterion = nn.CrossEntropyLoss()\n",
    "ao_optimizer = optim.Adam(ao_model.parameters(), lr=0.001)\n",
    "ao_scheduler = optim.lr_scheduler.StepLR(ao_optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "print_model_summary(ao_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Step 100/600, Loss: 1.0296\n",
      "Epoch 1/10, Step 200/600, Loss: 0.5742\n",
      "Epoch 1/10, Step 300/600, Loss: 0.4029\n",
      "Epoch 1/10, Step 400/600, Loss: 0.5613\n",
      "Epoch 1/10, Step 500/600, Loss: 0.4507\n",
      "Epoch 1/10, Step 600/600, Loss: 0.4192\n",
      "Epoch 1/10, Loss: 0.7544, Training Accuracy: 74.30%, Validation Accuracy: 97.70%\n",
      "\n",
      "Epoch 2/10, Step 100/600, Loss: 0.3705\n",
      "Epoch 2/10, Step 200/600, Loss: 0.3620\n",
      "Epoch 2/10, Step 300/600, Loss: 0.2650\n",
      "Epoch 2/10, Step 400/600, Loss: 0.3186\n",
      "Epoch 2/10, Step 500/600, Loss: 0.2915\n",
      "Epoch 2/10, Step 600/600, Loss: 0.3214\n",
      "Epoch 2/10, Loss: 0.3620, Training Accuracy: 88.19%, Validation Accuracy: 98.05%\n",
      "\n",
      "Epoch 3/10, Step 100/600, Loss: 0.2805\n",
      "Epoch 3/10, Step 200/600, Loss: 0.2241\n",
      "Epoch 3/10, Step 300/600, Loss: 0.3621\n",
      "Epoch 3/10, Step 400/600, Loss: 0.2215\n",
      "Epoch 3/10, Step 500/600, Loss: 0.2648\n",
      "Epoch 3/10, Step 600/600, Loss: 0.2723\n",
      "Epoch 3/10, Loss: 0.2998, Training Accuracy: 90.14%, Validation Accuracy: 98.47%\n",
      "\n",
      "Epoch 4/10, Step 100/600, Loss: 0.3066\n",
      "Epoch 4/10, Step 200/600, Loss: 0.2156\n",
      "Epoch 4/10, Step 300/600, Loss: 0.2317\n",
      "Epoch 4/10, Step 400/600, Loss: 0.3013\n",
      "Epoch 4/10, Step 500/600, Loss: 0.1903\n",
      "Epoch 4/10, Step 600/600, Loss: 0.1739\n",
      "Epoch 4/10, Loss: 0.2648, Training Accuracy: 91.41%, Validation Accuracy: 98.96%\n",
      "\n",
      "Epoch 5/10, Step 100/600, Loss: 0.4502\n",
      "Epoch 5/10, Step 200/600, Loss: 0.2780\n",
      "Epoch 5/10, Step 300/600, Loss: 0.2591\n",
      "Epoch 5/10, Step 400/600, Loss: 0.3081\n",
      "Epoch 5/10, Step 500/600, Loss: 0.3092\n",
      "Epoch 5/10, Step 600/600, Loss: 0.2417\n",
      "Epoch 5/10, Loss: 0.2377, Training Accuracy: 92.29%, Validation Accuracy: 98.49%\n",
      "\n",
      "Epoch 6/10, Step 100/600, Loss: 0.1824\n",
      "Epoch 6/10, Step 200/600, Loss: 0.1803\n",
      "Epoch 6/10, Step 300/600, Loss: 0.2598\n",
      "Epoch 6/10, Step 400/600, Loss: 0.1525\n",
      "Epoch 6/10, Step 500/600, Loss: 0.1800\n",
      "Epoch 6/10, Step 600/600, Loss: 0.2776\n",
      "Epoch 6/10, Loss: 0.2060, Training Accuracy: 93.36%, Validation Accuracy: 99.16%\n",
      "\n",
      "Epoch 7/10, Step 100/600, Loss: 0.1685\n",
      "Epoch 7/10, Step 200/600, Loss: 0.2466\n",
      "Epoch 7/10, Step 300/600, Loss: 0.1567\n",
      "Epoch 7/10, Step 400/600, Loss: 0.2073\n",
      "Epoch 7/10, Step 500/600, Loss: 0.3108\n",
      "Epoch 7/10, Step 600/600, Loss: 0.2010\n",
      "Epoch 7/10, Loss: 0.1933, Training Accuracy: 93.81%, Validation Accuracy: 98.97%\n",
      "\n",
      "Epoch 8/10, Step 100/600, Loss: 0.1514\n",
      "Epoch 8/10, Step 200/600, Loss: 0.1494\n",
      "Epoch 8/10, Step 300/600, Loss: 0.1361\n",
      "Epoch 8/10, Step 400/600, Loss: 0.1632\n",
      "Epoch 8/10, Step 500/600, Loss: 0.1451\n",
      "Epoch 8/10, Step 600/600, Loss: 0.3067\n",
      "Epoch 8/10, Loss: 0.1859, Training Accuracy: 93.97%, Validation Accuracy: 99.16%\n",
      "\n",
      "Epoch 9/10, Step 100/600, Loss: 0.2159\n",
      "Epoch 9/10, Step 200/600, Loss: 0.2101\n",
      "Epoch 9/10, Step 300/600, Loss: 0.3026\n",
      "Epoch 9/10, Step 400/600, Loss: 0.1422\n",
      "Epoch 9/10, Step 500/600, Loss: 0.1795\n",
      "Epoch 9/10, Step 600/600, Loss: 0.2260\n",
      "Epoch 9/10, Loss: 0.1841, Training Accuracy: 94.17%, Validation Accuracy: 99.19%\n",
      "\n",
      "Epoch 10/10, Step 100/600, Loss: 0.0836\n",
      "Epoch 10/10, Step 200/600, Loss: 0.2297\n",
      "Epoch 10/10, Step 300/600, Loss: 0.0936\n",
      "Epoch 10/10, Step 400/600, Loss: 0.2605\n",
      "Epoch 10/10, Step 500/600, Loss: 0.2217\n",
      "Epoch 10/10, Step 600/600, Loss: 0.2090\n",
      "Epoch 10/10, Loss: 0.1727, Training Accuracy: 94.22%, Validation Accuracy: 99.29%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(ao_model, ao_criterion, ao_optimizer, epochs=10, scheduler=ao_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTransform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Ensure single channel\n",
    "    transforms.Resize((28, 28)),  # Resize to 28x28 in case of any deviations\n",
    "    transforms.ToTensor(),  # Convert to tensor with range [0, 1]\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # mean and std of MNIST dataset\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def classify_image(model, image_path, transform, device):\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image).unsqueeze(0).to(device) \n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    return predicted.item()  # Return the predicted class as an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0.png -> Predicted Label: 8\n",
      "Image 1.png -> Predicted Label: 8\n",
      "Image 2.png -> Predicted Label: 8\n",
      "Image 3.png -> Predicted Label: 8\n",
      "Image 4.png -> Predicted Label: 8\n",
      "Image 5.png -> Predicted Label: 8\n",
      "Image 6.png -> Predicted Label: 8\n",
      "Image 7.png -> Predicted Label: 8\n",
      "Image 8.png -> Predicted Label: 8\n",
      "Image 9.png -> Predicted Label: 8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "ao_model.eval()\n",
    "\n",
    "folder_path = './MyMNIST'  \n",
    "for i in range(10):  # Assuming images are named 0.png to 9.png\n",
    "    image_path = os.path.join(folder_path, f\"{i}.png\")\n",
    "    prediction = classify_image(ao_model, image_path, myTransform, device)\n",
    "    print(f\"Image {i}.png -> Predicted Label: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
