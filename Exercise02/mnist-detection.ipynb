{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup\n",
    "\n",
    "Pytorch needs pythont 3.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 600\n",
      "Number of testing batches: 100\n"
     ]
    }
   ],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.RandomCrop(size=(28, 28), padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # mean and std of MNIST dataset\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # mean and std of MNIST dataset\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./../data', train=True, transform=train_transforms, download=True)\n",
    "test_dataset = datasets.MNIST(root='./../data', train=False, transform=test_transforms, download=True)\n",
    "\n",
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f'Number of training batches: {len(train_loader)}')\n",
    "print(f'Number of testing batches: {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Print Model Summary Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_summary(model):\n",
    "    def layer_summary(layer):\n",
    "        output_shape = None\n",
    "        if hasattr(layer, 'out_channels'):\n",
    "            output_shape = (layer.out_channels, \"H_out\", \"W_out\")\n",
    "        elif hasattr(layer, 'out_features'):\n",
    "            output_shape = (layer.out_features)\n",
    "        elif isinstance(layer, torch.nn.modules.pooling._MaxPoolNd):\n",
    "            output_shape = (layer.kernel_size, \"H_out\", \"W_out\")\n",
    "\n",
    "        num_params = sum(p.numel() for p in layer.parameters() if p.requires_grad)\n",
    "        return output_shape, num_params\n",
    "\n",
    "    model_name = model.__class__.__name__\n",
    "    print(f\"'{model_name}' Model Summary:\")\n",
    "\n",
    "    print(\"=\"*75)\n",
    "    print(f\"{'Layer':<30} {'Output Shape':<30} {'Param #':<15}\")\n",
    "    print(\"=\"*75)\n",
    "    \n",
    "    for name, layer in model.named_children():\n",
    "        output_shape, num_params = layer_summary(layer)\n",
    "        print(f\"{name:<30} {str(output_shape):<30} {num_params:<15}\")\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    print(\"=\"*75)\n",
    "    print(f\"Total params:          {total_params}\")\n",
    "    print(f\"Trainable params:      {trainable_params}\")\n",
    "    print(f\"Non-trainable params:  {total_params - trainable_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Train and Test Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, epochs, scheduler=None):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print(f'Epoch {epoch+1}/{epochs}, Step {i+1}/{len(train_loader)}, Loss: {loss.item()}')\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f'Accuracy: {correct / total * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Singlelayer Softmax Classifier\n",
    "\n",
    "from https://gist.github.com/dinhnguyenduc1994/b5881bf922054afb311b0c9a053c0357"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'SoftMax' Model Summary:\n",
      "===========================================================================\n",
      "Layer                          Output Shape                   Param #        \n",
      "===========================================================================\n",
      "linear                         10                             7850           \n",
      "===========================================================================\n",
      "Total params:          7850\n",
      "Trainable params:      7850\n",
      "Non-trainable params:  0\n"
     ]
    }
   ],
   "source": [
    "class SoftMax(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SoftMax, self).__init__()\n",
    "        self.linear = nn.Linear(28 * 28, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        z = self.linear(x)\n",
    "        return z\n",
    "    \n",
    "sl_model = SoftMax().to(device)\n",
    "sl_optimizer = torch.optim.SGD(sl_model.parameters(), lr=0.1)\n",
    "sl_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print_model_summary(sl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Step 100/600, Loss: 1.9170368909835815\n",
      "Epoch 1/20, Step 200/600, Loss: 1.9333980083465576\n",
      "Epoch 1/20, Step 300/600, Loss: 1.9247078895568848\n",
      "Epoch 1/20, Step 400/600, Loss: 1.7628065347671509\n",
      "Epoch 1/20, Step 500/600, Loss: 2.2719123363494873\n",
      "Epoch 1/20, Step 600/600, Loss: 2.4166715145111084\n",
      "Epoch 2/20, Step 100/600, Loss: 2.2451603412628174\n",
      "Epoch 2/20, Step 200/600, Loss: 1.6888362169265747\n",
      "Epoch 2/20, Step 300/600, Loss: 1.9403436183929443\n",
      "Epoch 2/20, Step 400/600, Loss: 2.018605947494507\n",
      "Epoch 2/20, Step 500/600, Loss: 1.9162933826446533\n",
      "Epoch 2/20, Step 600/600, Loss: 1.8245468139648438\n",
      "Epoch 3/20, Step 100/600, Loss: 1.8393642902374268\n",
      "Epoch 3/20, Step 200/600, Loss: 1.7934350967407227\n",
      "Epoch 3/20, Step 300/600, Loss: 1.7880862951278687\n",
      "Epoch 3/20, Step 400/600, Loss: 1.7706981897354126\n",
      "Epoch 3/20, Step 500/600, Loss: 2.1601662635803223\n",
      "Epoch 3/20, Step 600/600, Loss: 2.026421546936035\n",
      "Epoch 4/20, Step 100/600, Loss: 2.0866973400115967\n",
      "Epoch 4/20, Step 200/600, Loss: 1.9939258098602295\n",
      "Epoch 4/20, Step 300/600, Loss: 1.7542990446090698\n",
      "Epoch 4/20, Step 400/600, Loss: 1.9328380823135376\n",
      "Epoch 4/20, Step 500/600, Loss: 2.049276113510132\n",
      "Epoch 4/20, Step 600/600, Loss: 1.9981645345687866\n",
      "Epoch 5/20, Step 100/600, Loss: 2.0837199687957764\n",
      "Epoch 5/20, Step 200/600, Loss: 1.7800536155700684\n",
      "Epoch 5/20, Step 300/600, Loss: 2.1341543197631836\n",
      "Epoch 5/20, Step 400/600, Loss: 2.123201370239258\n",
      "Epoch 5/20, Step 500/600, Loss: 2.086404800415039\n",
      "Epoch 5/20, Step 600/600, Loss: 2.115997552871704\n",
      "Epoch 6/20, Step 100/600, Loss: 2.3119618892669678\n",
      "Epoch 6/20, Step 200/600, Loss: 2.1953623294830322\n",
      "Epoch 6/20, Step 300/600, Loss: 2.1222922801971436\n",
      "Epoch 6/20, Step 400/600, Loss: 1.762330174446106\n",
      "Epoch 6/20, Step 500/600, Loss: 1.9830169677734375\n",
      "Epoch 6/20, Step 600/600, Loss: 2.0664522647857666\n",
      "Epoch 7/20, Step 100/600, Loss: 1.9766350984573364\n",
      "Epoch 7/20, Step 200/600, Loss: 1.9488643407821655\n",
      "Epoch 7/20, Step 300/600, Loss: 1.886813998222351\n",
      "Epoch 7/20, Step 400/600, Loss: 1.72767972946167\n",
      "Epoch 7/20, Step 500/600, Loss: 2.0361692905426025\n",
      "Epoch 7/20, Step 600/600, Loss: 1.7032310962677002\n",
      "Epoch 8/20, Step 100/600, Loss: 1.9523882865905762\n",
      "Epoch 8/20, Step 200/600, Loss: 2.101980209350586\n",
      "Epoch 8/20, Step 300/600, Loss: 1.9398874044418335\n",
      "Epoch 8/20, Step 400/600, Loss: 2.222280502319336\n",
      "Epoch 8/20, Step 500/600, Loss: 1.7148430347442627\n",
      "Epoch 8/20, Step 600/600, Loss: 1.9671446084976196\n",
      "Epoch 9/20, Step 100/600, Loss: 2.069354772567749\n",
      "Epoch 9/20, Step 200/600, Loss: 1.9714351892471313\n",
      "Epoch 9/20, Step 300/600, Loss: 1.9806835651397705\n",
      "Epoch 9/20, Step 400/600, Loss: 1.9889585971832275\n",
      "Epoch 9/20, Step 500/600, Loss: 1.9683855772018433\n",
      "Epoch 9/20, Step 600/600, Loss: 2.080106019973755\n",
      "Epoch 10/20, Step 100/600, Loss: 2.082552671432495\n",
      "Epoch 10/20, Step 200/600, Loss: 2.010366678237915\n",
      "Epoch 10/20, Step 300/600, Loss: 2.092400074005127\n",
      "Epoch 10/20, Step 400/600, Loss: 2.1542601585388184\n",
      "Epoch 10/20, Step 500/600, Loss: 1.9626764059066772\n",
      "Epoch 10/20, Step 600/600, Loss: 2.104504346847534\n",
      "Epoch 11/20, Step 100/600, Loss: 1.6941241025924683\n",
      "Epoch 11/20, Step 200/600, Loss: 1.9172461032867432\n",
      "Epoch 11/20, Step 300/600, Loss: 2.0359678268432617\n",
      "Epoch 11/20, Step 400/600, Loss: 1.9180881977081299\n",
      "Epoch 11/20, Step 500/600, Loss: 1.799689531326294\n",
      "Epoch 11/20, Step 600/600, Loss: 2.0351853370666504\n",
      "Epoch 12/20, Step 100/600, Loss: 1.9993144273757935\n",
      "Epoch 12/20, Step 200/600, Loss: 1.8518861532211304\n",
      "Epoch 12/20, Step 300/600, Loss: 1.9939368963241577\n",
      "Epoch 12/20, Step 400/600, Loss: 1.7971665859222412\n",
      "Epoch 12/20, Step 500/600, Loss: 1.6607215404510498\n",
      "Epoch 12/20, Step 600/600, Loss: 1.9019798040390015\n",
      "Epoch 13/20, Step 100/600, Loss: 1.7433894872665405\n",
      "Epoch 13/20, Step 200/600, Loss: 2.0255560874938965\n",
      "Epoch 13/20, Step 300/600, Loss: 2.1129310131073\n",
      "Epoch 13/20, Step 400/600, Loss: 2.1936349868774414\n",
      "Epoch 13/20, Step 500/600, Loss: 1.8369311094284058\n",
      "Epoch 13/20, Step 600/600, Loss: 1.996645450592041\n",
      "Epoch 14/20, Step 100/600, Loss: 1.8300178050994873\n",
      "Epoch 14/20, Step 200/600, Loss: 2.0409116744995117\n",
      "Epoch 14/20, Step 300/600, Loss: 1.8110265731811523\n",
      "Epoch 14/20, Step 400/600, Loss: 2.0282812118530273\n",
      "Epoch 14/20, Step 500/600, Loss: 1.9538623094558716\n",
      "Epoch 14/20, Step 600/600, Loss: 1.9818187952041626\n",
      "Epoch 15/20, Step 100/600, Loss: 2.0685009956359863\n",
      "Epoch 15/20, Step 200/600, Loss: 1.9180402755737305\n",
      "Epoch 15/20, Step 300/600, Loss: 1.9576956033706665\n",
      "Epoch 15/20, Step 400/600, Loss: 2.013404130935669\n",
      "Epoch 15/20, Step 500/600, Loss: 1.8127740621566772\n",
      "Epoch 15/20, Step 600/600, Loss: 2.147933006286621\n",
      "Epoch 16/20, Step 100/600, Loss: 1.9146651029586792\n",
      "Epoch 16/20, Step 200/600, Loss: 1.8515691757202148\n",
      "Epoch 16/20, Step 300/600, Loss: 1.9435715675354004\n",
      "Epoch 16/20, Step 400/600, Loss: 1.9611482620239258\n",
      "Epoch 16/20, Step 500/600, Loss: 1.782891869544983\n",
      "Epoch 16/20, Step 600/600, Loss: 1.9106285572052002\n",
      "Epoch 17/20, Step 100/600, Loss: 2.1640846729278564\n",
      "Epoch 17/20, Step 200/600, Loss: 1.9705865383148193\n",
      "Epoch 17/20, Step 300/600, Loss: 2.1502106189727783\n",
      "Epoch 17/20, Step 400/600, Loss: 2.022090196609497\n",
      "Epoch 17/20, Step 500/600, Loss: 1.7773131132125854\n",
      "Epoch 17/20, Step 600/600, Loss: 1.8121380805969238\n",
      "Epoch 18/20, Step 100/600, Loss: 2.1417462825775146\n",
      "Epoch 18/20, Step 200/600, Loss: 2.0095937252044678\n",
      "Epoch 18/20, Step 300/600, Loss: 2.2231876850128174\n",
      "Epoch 18/20, Step 400/600, Loss: 2.029876470565796\n",
      "Epoch 18/20, Step 500/600, Loss: 2.0761518478393555\n",
      "Epoch 18/20, Step 600/600, Loss: 2.039505958557129\n",
      "Epoch 19/20, Step 100/600, Loss: 1.925290584564209\n",
      "Epoch 19/20, Step 200/600, Loss: 2.0325357913970947\n",
      "Epoch 19/20, Step 300/600, Loss: 2.076826572418213\n",
      "Epoch 19/20, Step 400/600, Loss: 1.9540894031524658\n",
      "Epoch 19/20, Step 500/600, Loss: 1.9420967102050781\n",
      "Epoch 19/20, Step 600/600, Loss: 1.9617395401000977\n",
      "Epoch 20/20, Step 100/600, Loss: 1.9500513076782227\n",
      "Epoch 20/20, Step 200/600, Loss: 2.2465567588806152\n",
      "Epoch 20/20, Step 300/600, Loss: 2.149768590927124\n",
      "Epoch 20/20, Step 400/600, Loss: 1.8517680168151855\n",
      "Epoch 20/20, Step 500/600, Loss: 2.129600763320923\n",
      "Epoch 20/20, Step 600/600, Loss: 2.1453893184661865\n",
      "Accuracy: 43.8%\n"
     ]
    }
   ],
   "source": [
    "train(sl_model, sl_criterion, sl_optimizer, epochs=20)\n",
    "test(sl_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'SimpleCNN' Model Summary:\n",
      "===========================================================================\n",
      "Layer                          Output Shape                   Param #        \n",
      "===========================================================================\n",
      "conv1                          (32, 'H_out', 'W_out')         320            \n",
      "pool                           (2, 'H_out', 'W_out')          0              \n",
      "fc1                            64                             401472         \n",
      "fc2                            10                             650            \n",
      "===========================================================================\n",
      "Total params:          402442\n",
      "Trainable params:      402442\n",
      "Non-trainable params:  0\n"
     ]
    }
   ],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(32 * 14 * 14, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "\n",
    "        x = x.view(-1, 32 * 14 * 14) # Flatten the tensor\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "simple_model = SimpleCNN().to(device)\n",
    "simple_criterion = nn.CrossEntropyLoss()\n",
    "simple_optimizer = optim.Adam(simple_model.parameters(), lr=0.001)\n",
    "\n",
    "print_model_summary(simple_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Step 100/600, Loss: 1.3722882270812988\n",
      "Epoch 1/20, Step 200/600, Loss: 0.7854834794998169\n",
      "Epoch 1/20, Step 300/600, Loss: 0.6508156061172485\n",
      "Epoch 1/20, Step 400/600, Loss: 0.5874542593955994\n",
      "Epoch 1/20, Step 500/600, Loss: 0.5449044704437256\n",
      "Epoch 1/20, Step 600/600, Loss: 0.446777880191803\n",
      "Epoch 2/20, Step 100/600, Loss: 0.3448336124420166\n",
      "Epoch 2/20, Step 200/600, Loss: 0.3206726014614105\n",
      "Epoch 2/20, Step 300/600, Loss: 0.31378573179244995\n",
      "Epoch 2/20, Step 400/600, Loss: 0.3655962347984314\n",
      "Epoch 2/20, Step 500/600, Loss: 0.46703147888183594\n",
      "Epoch 2/20, Step 600/600, Loss: 0.6107413172721863\n",
      "Epoch 3/20, Step 100/600, Loss: 0.3311033248901367\n",
      "Epoch 3/20, Step 200/600, Loss: 0.287320077419281\n",
      "Epoch 3/20, Step 300/600, Loss: 0.4268115162849426\n",
      "Epoch 3/20, Step 400/600, Loss: 0.26430168747901917\n",
      "Epoch 3/20, Step 500/600, Loss: 0.425217866897583\n",
      "Epoch 3/20, Step 600/600, Loss: 0.3057456314563751\n",
      "Epoch 4/20, Step 100/600, Loss: 0.29623669385910034\n",
      "Epoch 4/20, Step 200/600, Loss: 0.2203543782234192\n",
      "Epoch 4/20, Step 300/600, Loss: 0.23699067533016205\n",
      "Epoch 4/20, Step 400/600, Loss: 0.17336422204971313\n",
      "Epoch 4/20, Step 500/600, Loss: 0.2599259912967682\n",
      "Epoch 4/20, Step 600/600, Loss: 0.3204364478588104\n",
      "Epoch 5/20, Step 100/600, Loss: 0.3091527223587036\n",
      "Epoch 5/20, Step 200/600, Loss: 0.19825491309165955\n",
      "Epoch 5/20, Step 300/600, Loss: 0.19663593173027039\n",
      "Epoch 5/20, Step 400/600, Loss: 0.14185816049575806\n",
      "Epoch 5/20, Step 500/600, Loss: 0.2112272083759308\n",
      "Epoch 5/20, Step 600/600, Loss: 0.2675637900829315\n",
      "Epoch 6/20, Step 100/600, Loss: 0.09824178367853165\n",
      "Epoch 6/20, Step 200/600, Loss: 0.2271130383014679\n",
      "Epoch 6/20, Step 300/600, Loss: 0.182681605219841\n",
      "Epoch 6/20, Step 400/600, Loss: 0.18300926685333252\n",
      "Epoch 6/20, Step 500/600, Loss: 0.1671956181526184\n",
      "Epoch 6/20, Step 600/600, Loss: 0.2091568559408188\n",
      "Epoch 7/20, Step 100/600, Loss: 0.20610064268112183\n",
      "Epoch 7/20, Step 200/600, Loss: 0.27948132157325745\n",
      "Epoch 7/20, Step 300/600, Loss: 0.3798472583293915\n",
      "Epoch 7/20, Step 400/600, Loss: 0.08418024331331253\n",
      "Epoch 7/20, Step 500/600, Loss: 0.16474981606006622\n",
      "Epoch 7/20, Step 600/600, Loss: 0.08459111303091049\n",
      "Epoch 8/20, Step 100/600, Loss: 0.2151954621076584\n",
      "Epoch 8/20, Step 200/600, Loss: 0.15630418062210083\n",
      "Epoch 8/20, Step 300/600, Loss: 0.25514325499534607\n",
      "Epoch 8/20, Step 400/600, Loss: 0.2875973582267761\n",
      "Epoch 8/20, Step 500/600, Loss: 0.2258913367986679\n",
      "Epoch 8/20, Step 600/600, Loss: 0.32873550057411194\n",
      "Epoch 9/20, Step 100/600, Loss: 0.15768319368362427\n",
      "Epoch 9/20, Step 200/600, Loss: 0.10235307365655899\n",
      "Epoch 9/20, Step 300/600, Loss: 0.13106565177440643\n",
      "Epoch 9/20, Step 400/600, Loss: 0.2902251183986664\n",
      "Epoch 9/20, Step 500/600, Loss: 0.13835495710372925\n",
      "Epoch 9/20, Step 600/600, Loss: 0.11412361264228821\n",
      "Epoch 10/20, Step 100/600, Loss: 0.19930081069469452\n",
      "Epoch 10/20, Step 200/600, Loss: 0.1428404003381729\n",
      "Epoch 10/20, Step 300/600, Loss: 0.13942641019821167\n",
      "Epoch 10/20, Step 400/600, Loss: 0.2310141623020172\n",
      "Epoch 10/20, Step 500/600, Loss: 0.2177233248949051\n",
      "Epoch 10/20, Step 600/600, Loss: 0.1886797547340393\n",
      "Epoch 11/20, Step 100/600, Loss: 0.22797687351703644\n",
      "Epoch 11/20, Step 200/600, Loss: 0.1294160634279251\n",
      "Epoch 11/20, Step 300/600, Loss: 0.19754819571971893\n",
      "Epoch 11/20, Step 400/600, Loss: 0.24082665145397186\n",
      "Epoch 11/20, Step 500/600, Loss: 0.12459040433168411\n",
      "Epoch 11/20, Step 600/600, Loss: 0.16507378220558167\n",
      "Epoch 12/20, Step 100/600, Loss: 0.1390373557806015\n",
      "Epoch 12/20, Step 200/600, Loss: 0.08354558795690536\n",
      "Epoch 12/20, Step 300/600, Loss: 0.16606491804122925\n",
      "Epoch 12/20, Step 400/600, Loss: 0.08533436059951782\n",
      "Epoch 12/20, Step 500/600, Loss: 0.16145473718643188\n",
      "Epoch 12/20, Step 600/600, Loss: 0.15862935781478882\n",
      "Epoch 13/20, Step 100/600, Loss: 0.1496821939945221\n",
      "Epoch 13/20, Step 200/600, Loss: 0.17800690233707428\n",
      "Epoch 13/20, Step 300/600, Loss: 0.18734802305698395\n",
      "Epoch 13/20, Step 400/600, Loss: 0.0777287557721138\n",
      "Epoch 13/20, Step 500/600, Loss: 0.08114799857139587\n",
      "Epoch 13/20, Step 600/600, Loss: 0.17833730578422546\n",
      "Epoch 14/20, Step 100/600, Loss: 0.13387450575828552\n",
      "Epoch 14/20, Step 200/600, Loss: 0.09242074191570282\n",
      "Epoch 14/20, Step 300/600, Loss: 0.16682997345924377\n",
      "Epoch 14/20, Step 400/600, Loss: 0.08632894605398178\n",
      "Epoch 14/20, Step 500/600, Loss: 0.24932798743247986\n",
      "Epoch 14/20, Step 600/600, Loss: 0.22436371445655823\n",
      "Epoch 15/20, Step 100/600, Loss: 0.17099732160568237\n",
      "Epoch 15/20, Step 200/600, Loss: 0.14601226150989532\n",
      "Epoch 15/20, Step 300/600, Loss: 0.10045171529054642\n",
      "Epoch 15/20, Step 400/600, Loss: 0.23959146440029144\n",
      "Epoch 15/20, Step 500/600, Loss: 0.11762792617082596\n",
      "Epoch 15/20, Step 600/600, Loss: 0.15316131711006165\n",
      "Epoch 16/20, Step 100/600, Loss: 0.23166947066783905\n",
      "Epoch 16/20, Step 200/600, Loss: 0.12595495581626892\n",
      "Epoch 16/20, Step 300/600, Loss: 0.1696188598871231\n",
      "Epoch 16/20, Step 400/600, Loss: 0.07494707405567169\n",
      "Epoch 16/20, Step 500/600, Loss: 0.13948360085487366\n",
      "Epoch 16/20, Step 600/600, Loss: 0.14854349195957184\n",
      "Epoch 17/20, Step 100/600, Loss: 0.337246298789978\n",
      "Epoch 17/20, Step 200/600, Loss: 0.16293968260288239\n",
      "Epoch 17/20, Step 300/600, Loss: 0.16566333174705505\n",
      "Epoch 17/20, Step 400/600, Loss: 0.14204829931259155\n",
      "Epoch 17/20, Step 500/600, Loss: 0.13202504813671112\n",
      "Epoch 17/20, Step 600/600, Loss: 0.133370041847229\n",
      "Epoch 18/20, Step 100/600, Loss: 0.10956514626741409\n",
      "Epoch 18/20, Step 200/600, Loss: 0.14406348764896393\n",
      "Epoch 18/20, Step 300/600, Loss: 0.2557751536369324\n",
      "Epoch 18/20, Step 400/600, Loss: 0.11692862212657928\n",
      "Epoch 18/20, Step 500/600, Loss: 0.09091929346323013\n",
      "Epoch 18/20, Step 600/600, Loss: 0.15575343370437622\n",
      "Epoch 19/20, Step 100/600, Loss: 0.19208163022994995\n",
      "Epoch 19/20, Step 200/600, Loss: 0.1782292127609253\n",
      "Epoch 19/20, Step 300/600, Loss: 0.11646769195795059\n",
      "Epoch 19/20, Step 400/600, Loss: 0.1836344301700592\n",
      "Epoch 19/20, Step 500/600, Loss: 0.0647146999835968\n",
      "Epoch 19/20, Step 600/600, Loss: 0.09912380576133728\n",
      "Epoch 20/20, Step 100/600, Loss: 0.08905485272407532\n",
      "Epoch 20/20, Step 200/600, Loss: 0.12793992459774017\n",
      "Epoch 20/20, Step 300/600, Loss: 0.208656907081604\n",
      "Epoch 20/20, Step 400/600, Loss: 0.07915052026510239\n",
      "Epoch 20/20, Step 500/600, Loss: 0.18161645531654358\n",
      "Epoch 20/20, Step 600/600, Loss: 0.08024712651968002\n",
      "Accuracy: 97.94%\n"
     ]
    }
   ],
   "source": [
    "train(simple_model, simple_criterion, simple_optimizer, epochs=20)\n",
    "test(simple_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Accuracy Optimized CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'AccuracyOptimCNN' Model Summary:\n",
      "===========================================================================\n",
      "Layer                          Output Shape                   Param #        \n",
      "===========================================================================\n",
      "conv1                          (32, 'H_out', 'W_out')         320            \n",
      "conv2                          (64, 'H_out', 'W_out')         18496          \n",
      "conv3                          (32, 'H_out', 'W_out')         18464          \n",
      "conv4                          (64, 'H_out', 'W_out')         18496          \n",
      "bn1                            None                           64             \n",
      "bn2                            None                           128            \n",
      "bn3                            None                           64             \n",
      "bn4                            None                           128            \n",
      "pool                           (2, 'H_out', 'W_out')          0              \n",
      "dropout1                       None                           0              \n",
      "fc1                            64                             200768         \n",
      "dropout2                       None                           0              \n",
      "fc2                            10                             650            \n",
      "===========================================================================\n",
      "Total params:          257578\n",
      "Trainable params:      257578\n",
      "Non-trainable params:  0\n"
     ]
    }
   ],
   "source": [
    "class AccuracyOptimCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AccuracyOptimCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 64)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.conv1(x)))\n",
    "        x = torch.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.view(-1, 64 * 7 * 7) # Flatten the tensor\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "ao_model = AccuracyOptimCNN().to(device)\n",
    "ao_criterion = nn.CrossEntropyLoss()\n",
    "ao_optimizer = optim.Adam(ao_model.parameters(), lr=0.001)\n",
    "ao_scheduler = optim.lr_scheduler.StepLR(ao_optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "print_model_summary(ao_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Step 100/600, Loss: 1.7012524604797363\n",
      "Epoch 1/20, Step 200/600, Loss: 1.1781768798828125\n",
      "Epoch 1/20, Step 300/600, Loss: 0.7821168303489685\n",
      "Epoch 1/20, Step 400/600, Loss: 0.9377439618110657\n",
      "Epoch 1/20, Step 500/600, Loss: 0.9829246997833252\n",
      "Epoch 1/20, Step 600/600, Loss: 0.9114763736724854\n",
      "Epoch 2/20, Step 100/600, Loss: 0.7381716966629028\n",
      "Epoch 2/20, Step 200/600, Loss: 0.8888132572174072\n",
      "Epoch 2/20, Step 300/600, Loss: 0.7536575794219971\n",
      "Epoch 2/20, Step 400/600, Loss: 0.6089790463447571\n",
      "Epoch 2/20, Step 500/600, Loss: 0.9550453424453735\n",
      "Epoch 2/20, Step 600/600, Loss: 0.4485337734222412\n",
      "Epoch 3/20, Step 100/600, Loss: 0.4952573776245117\n",
      "Epoch 3/20, Step 200/600, Loss: 0.688212513923645\n",
      "Epoch 3/20, Step 300/600, Loss: 0.6882531642913818\n",
      "Epoch 3/20, Step 400/600, Loss: 0.7205285429954529\n",
      "Epoch 3/20, Step 500/600, Loss: 0.5526673197746277\n",
      "Epoch 3/20, Step 600/600, Loss: 0.665091872215271\n",
      "Epoch 4/20, Step 100/600, Loss: 0.7612094879150391\n",
      "Epoch 4/20, Step 200/600, Loss: 0.6227653622627258\n",
      "Epoch 4/20, Step 300/600, Loss: 0.6593908071517944\n",
      "Epoch 4/20, Step 400/600, Loss: 0.501571774482727\n",
      "Epoch 4/20, Step 500/600, Loss: 0.5207488536834717\n",
      "Epoch 4/20, Step 600/600, Loss: 0.4654509723186493\n",
      "Epoch 5/20, Step 100/600, Loss: 0.5754207372665405\n",
      "Epoch 5/20, Step 200/600, Loss: 0.500539243221283\n",
      "Epoch 5/20, Step 300/600, Loss: 0.6503912210464478\n",
      "Epoch 5/20, Step 400/600, Loss: 0.5896865725517273\n",
      "Epoch 5/20, Step 500/600, Loss: 0.4875469207763672\n",
      "Epoch 5/20, Step 600/600, Loss: 0.4933698773384094\n",
      "Epoch 6/20, Step 100/600, Loss: 0.6656787395477295\n",
      "Epoch 6/20, Step 200/600, Loss: 0.4923383295536041\n",
      "Epoch 6/20, Step 300/600, Loss: 0.3832818269729614\n",
      "Epoch 6/20, Step 400/600, Loss: 0.5279085040092468\n",
      "Epoch 6/20, Step 500/600, Loss: 0.4855648875236511\n",
      "Epoch 6/20, Step 600/600, Loss: 0.3093622028827667\n",
      "Epoch 7/20, Step 100/600, Loss: 0.5231834053993225\n",
      "Epoch 7/20, Step 200/600, Loss: 0.35695910453796387\n",
      "Epoch 7/20, Step 300/600, Loss: 0.5990080237388611\n",
      "Epoch 7/20, Step 400/600, Loss: 0.5147045254707336\n",
      "Epoch 7/20, Step 500/600, Loss: 0.41256439685821533\n",
      "Epoch 7/20, Step 600/600, Loss: 0.45020169019699097\n",
      "Epoch 8/20, Step 100/600, Loss: 0.5261223912239075\n",
      "Epoch 8/20, Step 200/600, Loss: 0.4419953525066376\n",
      "Epoch 8/20, Step 300/600, Loss: 0.41935011744499207\n",
      "Epoch 8/20, Step 400/600, Loss: 0.46122342348098755\n",
      "Epoch 8/20, Step 500/600, Loss: 0.5257815718650818\n",
      "Epoch 8/20, Step 600/600, Loss: 0.3210586905479431\n",
      "Epoch 9/20, Step 100/600, Loss: 0.4965039789676666\n",
      "Epoch 9/20, Step 200/600, Loss: 0.5237593650817871\n",
      "Epoch 9/20, Step 300/600, Loss: 0.5210254788398743\n",
      "Epoch 9/20, Step 400/600, Loss: 0.489267498254776\n",
      "Epoch 9/20, Step 500/600, Loss: 0.442576140165329\n",
      "Epoch 9/20, Step 600/600, Loss: 0.36599960923194885\n",
      "Epoch 10/20, Step 100/600, Loss: 0.4250841438770294\n",
      "Epoch 10/20, Step 200/600, Loss: 0.4187529683113098\n",
      "Epoch 10/20, Step 300/600, Loss: 0.4983716309070587\n",
      "Epoch 10/20, Step 400/600, Loss: 0.5935819745063782\n",
      "Epoch 10/20, Step 500/600, Loss: 0.46579158306121826\n",
      "Epoch 10/20, Step 600/600, Loss: 0.527553915977478\n",
      "Epoch 11/20, Step 100/600, Loss: 0.39927056431770325\n",
      "Epoch 11/20, Step 200/600, Loss: 0.40687820315361023\n",
      "Epoch 11/20, Step 300/600, Loss: 0.47481659054756165\n",
      "Epoch 11/20, Step 400/600, Loss: 0.5077319145202637\n",
      "Epoch 11/20, Step 500/600, Loss: 0.474907785654068\n",
      "Epoch 11/20, Step 600/600, Loss: 0.5937215685844421\n",
      "Epoch 12/20, Step 100/600, Loss: 0.5483423471450806\n",
      "Epoch 12/20, Step 200/600, Loss: 0.4214654266834259\n",
      "Epoch 12/20, Step 300/600, Loss: 0.44163745641708374\n",
      "Epoch 12/20, Step 400/600, Loss: 0.6092322468757629\n",
      "Epoch 12/20, Step 500/600, Loss: 0.6523723602294922\n",
      "Epoch 12/20, Step 600/600, Loss: 0.5251747369766235\n",
      "Epoch 13/20, Step 100/600, Loss: 0.7694772481918335\n",
      "Epoch 13/20, Step 200/600, Loss: 0.5237331390380859\n",
      "Epoch 13/20, Step 300/600, Loss: 0.4532373547554016\n",
      "Epoch 13/20, Step 400/600, Loss: 0.37572869658470154\n",
      "Epoch 13/20, Step 500/600, Loss: 0.5322397351264954\n",
      "Epoch 13/20, Step 600/600, Loss: 0.39217132329940796\n",
      "Epoch 14/20, Step 100/600, Loss: 0.5034169554710388\n",
      "Epoch 14/20, Step 200/600, Loss: 0.5508836507797241\n",
      "Epoch 14/20, Step 300/600, Loss: 0.42713358998298645\n",
      "Epoch 14/20, Step 400/600, Loss: 0.3385664224624634\n",
      "Epoch 14/20, Step 500/600, Loss: 0.6831567287445068\n",
      "Epoch 14/20, Step 600/600, Loss: 0.44819802045822144\n",
      "Epoch 15/20, Step 100/600, Loss: 0.6006852984428406\n",
      "Epoch 15/20, Step 200/600, Loss: 0.4917612075805664\n",
      "Epoch 15/20, Step 300/600, Loss: 0.4217531681060791\n",
      "Epoch 15/20, Step 400/600, Loss: 0.5870857834815979\n",
      "Epoch 15/20, Step 500/600, Loss: 0.3999512791633606\n",
      "Epoch 15/20, Step 600/600, Loss: 0.5134702324867249\n",
      "Epoch 16/20, Step 100/600, Loss: 0.3120627701282501\n",
      "Epoch 16/20, Step 200/600, Loss: 0.5547412037849426\n",
      "Epoch 16/20, Step 300/600, Loss: 0.37229669094085693\n",
      "Epoch 16/20, Step 400/600, Loss: 0.584480345249176\n",
      "Epoch 16/20, Step 500/600, Loss: 0.31767356395721436\n",
      "Epoch 16/20, Step 600/600, Loss: 0.35689276456832886\n",
      "Epoch 17/20, Step 100/600, Loss: 0.4520345628261566\n",
      "Epoch 17/20, Step 200/600, Loss: 0.4144532084465027\n",
      "Epoch 17/20, Step 300/600, Loss: 0.5697697401046753\n",
      "Epoch 17/20, Step 400/600, Loss: 0.42844024300575256\n",
      "Epoch 17/20, Step 500/600, Loss: 0.4411020576953888\n",
      "Epoch 17/20, Step 600/600, Loss: 0.5461339354515076\n",
      "Epoch 18/20, Step 100/600, Loss: 0.49178358912467957\n",
      "Epoch 18/20, Step 200/600, Loss: 0.4207359254360199\n",
      "Epoch 18/20, Step 300/600, Loss: 0.34754058718681335\n",
      "Epoch 18/20, Step 400/600, Loss: 0.7967369556427002\n",
      "Epoch 18/20, Step 500/600, Loss: 0.5442753434181213\n",
      "Epoch 18/20, Step 600/600, Loss: 0.4116334915161133\n",
      "Epoch 19/20, Step 100/600, Loss: 0.5044696927070618\n",
      "Epoch 19/20, Step 200/600, Loss: 0.4961795508861542\n",
      "Epoch 19/20, Step 300/600, Loss: 0.3953287899494171\n",
      "Epoch 19/20, Step 400/600, Loss: 0.32043421268463135\n",
      "Epoch 19/20, Step 500/600, Loss: 0.446600079536438\n",
      "Epoch 19/20, Step 600/600, Loss: 0.5337451696395874\n",
      "Epoch 20/20, Step 100/600, Loss: 0.48833000659942627\n",
      "Epoch 20/20, Step 200/600, Loss: 0.4670184254646301\n",
      "Epoch 20/20, Step 300/600, Loss: 0.522704005241394\n",
      "Epoch 20/20, Step 400/600, Loss: 0.375135600566864\n",
      "Epoch 20/20, Step 500/600, Loss: 0.4589621424674988\n",
      "Epoch 20/20, Step 600/600, Loss: 0.5988996624946594\n",
      "Accuracy: 99.22999999999999%\n"
     ]
    }
   ],
   "source": [
    "train(ao_model, ao_criterion, ao_optimizer, epochs=20, scheduler=ao_scheduler)\n",
    "test(ao_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Parameters Optimized CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'LeastParamsCNN' Model Summary:\n",
      "===========================================================================\n",
      "Layer                          Output Shape                   Param #        \n",
      "===========================================================================\n",
      "conv1                          (8, 'H_out', 'W_out')          80             \n",
      "conv2                          (8, 'H_out', 'W_out')          80             \n",
      "conv2_pointwise                (16, 'H_out', 'W_out')         144            \n",
      "conv3                          (16, 'H_out', 'W_out')         160            \n",
      "conv3_pointwise                (32, 'H_out', 'W_out')         544            \n",
      "bn1                            None                           16             \n",
      "bn2                            None                           32             \n",
      "bn3                            None                           64             \n",
      "pool                           (2, 'H_out', 'W_out')          0              \n",
      "fc1                            16                             4624           \n",
      "fc2                            10                             170            \n",
      "===========================================================================\n",
      "Total params:          5914\n",
      "Trainable params:      5914\n",
      "Non-trainable params:  0\n"
     ]
    }
   ],
   "source": [
    "class LeastParamsCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeastParamsCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3, stride=1, padding=1, groups=8)\n",
    "        self.conv2_pointwise = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=1) \n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1, groups=16)\n",
    "        self.conv3_pointwise = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        self.fc1 = nn.Linear(32 * 3 * 3, 16)\n",
    "        self.fc2 = nn.Linear(16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.bn2(self.conv2_pointwise(self.conv2(x))))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.bn3(self.conv3_pointwise(self.conv3(x))))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.view(-1, 32 * 3 * 3) # Flatten the tensor\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "lp_model = LeastParamsCNN().to(device)\n",
    "lp_criterion = nn.CrossEntropyLoss()\n",
    "lp_optimizer = optim.Adam(lp_model.parameters(), lr=0.001)\n",
    "lp_scheduler = optim.lr_scheduler.StepLR(lp_optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "print_model_summary(lp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Step 100/600, Loss: 1.3906863927841187\n",
      "Epoch 1/20, Step 200/600, Loss: 0.8284105658531189\n",
      "Epoch 1/20, Step 300/600, Loss: 0.8900453448295593\n",
      "Epoch 1/20, Step 400/600, Loss: 0.5031629800796509\n",
      "Epoch 1/20, Step 500/600, Loss: 0.4270351529121399\n",
      "Epoch 1/20, Step 600/600, Loss: 0.4711875021457672\n",
      "Epoch 2/20, Step 100/600, Loss: 0.3393630087375641\n",
      "Epoch 2/20, Step 200/600, Loss: 0.26549991965293884\n",
      "Epoch 2/20, Step 300/600, Loss: 0.2750595808029175\n",
      "Epoch 2/20, Step 400/600, Loss: 0.33409905433654785\n",
      "Epoch 2/20, Step 500/600, Loss: 0.32548826932907104\n",
      "Epoch 2/20, Step 600/600, Loss: 0.24065403640270233\n",
      "Epoch 3/20, Step 100/600, Loss: 0.23973405361175537\n",
      "Epoch 3/20, Step 200/600, Loss: 0.20622731745243073\n",
      "Epoch 3/20, Step 300/600, Loss: 0.20666471123695374\n",
      "Epoch 3/20, Step 400/600, Loss: 0.26085391640663147\n",
      "Epoch 3/20, Step 500/600, Loss: 0.3836088180541992\n",
      "Epoch 3/20, Step 600/600, Loss: 0.5467283129692078\n",
      "Epoch 4/20, Step 100/600, Loss: 0.24843847751617432\n",
      "Epoch 4/20, Step 200/600, Loss: 0.20396482944488525\n",
      "Epoch 4/20, Step 300/600, Loss: 0.2139643281698227\n",
      "Epoch 4/20, Step 400/600, Loss: 0.25179532170295715\n",
      "Epoch 4/20, Step 500/600, Loss: 0.3054253160953522\n",
      "Epoch 4/20, Step 600/600, Loss: 0.14885492622852325\n",
      "Epoch 5/20, Step 100/600, Loss: 0.2349107563495636\n",
      "Epoch 5/20, Step 200/600, Loss: 0.14018669724464417\n",
      "Epoch 5/20, Step 300/600, Loss: 0.16887331008911133\n",
      "Epoch 5/20, Step 400/600, Loss: 0.15186436474323273\n",
      "Epoch 5/20, Step 500/600, Loss: 0.34618204832077026\n",
      "Epoch 5/20, Step 600/600, Loss: 0.08150815218687057\n",
      "Epoch 6/20, Step 100/600, Loss: 0.1877824366092682\n",
      "Epoch 6/20, Step 200/600, Loss: 0.1991364061832428\n",
      "Epoch 6/20, Step 300/600, Loss: 0.3032388985157013\n",
      "Epoch 6/20, Step 400/600, Loss: 0.18628166615962982\n",
      "Epoch 6/20, Step 500/600, Loss: 0.1346902996301651\n",
      "Epoch 6/20, Step 600/600, Loss: 0.1342611461877823\n",
      "Epoch 7/20, Step 100/600, Loss: 0.2904627323150635\n",
      "Epoch 7/20, Step 200/600, Loss: 0.14785341918468475\n",
      "Epoch 7/20, Step 300/600, Loss: 0.21607328951358795\n",
      "Epoch 7/20, Step 400/600, Loss: 0.23498323559761047\n",
      "Epoch 7/20, Step 500/600, Loss: 0.19459779560565948\n",
      "Epoch 7/20, Step 600/600, Loss: 0.16451245546340942\n",
      "Epoch 8/20, Step 100/600, Loss: 0.16431979835033417\n",
      "Epoch 8/20, Step 200/600, Loss: 0.29372233152389526\n",
      "Epoch 8/20, Step 300/600, Loss: 0.22095103561878204\n",
      "Epoch 8/20, Step 400/600, Loss: 0.1399727463722229\n",
      "Epoch 8/20, Step 500/600, Loss: 0.154085174202919\n",
      "Epoch 8/20, Step 600/600, Loss: 0.13741004467010498\n",
      "Epoch 9/20, Step 100/600, Loss: 0.1521136462688446\n",
      "Epoch 9/20, Step 200/600, Loss: 0.05207834765315056\n",
      "Epoch 9/20, Step 300/600, Loss: 0.1378641575574875\n",
      "Epoch 9/20, Step 400/600, Loss: 0.08143465965986252\n",
      "Epoch 9/20, Step 500/600, Loss: 0.12206289172172546\n",
      "Epoch 9/20, Step 600/600, Loss: 0.20106253027915955\n",
      "Epoch 10/20, Step 100/600, Loss: 0.1116260439157486\n",
      "Epoch 10/20, Step 200/600, Loss: 0.062486790120601654\n",
      "Epoch 10/20, Step 300/600, Loss: 0.11293568462133408\n",
      "Epoch 10/20, Step 400/600, Loss: 0.13885223865509033\n",
      "Epoch 10/20, Step 500/600, Loss: 0.18459218740463257\n",
      "Epoch 10/20, Step 600/600, Loss: 0.14634057879447937\n",
      "Epoch 11/20, Step 100/600, Loss: 0.09190572798252106\n",
      "Epoch 11/20, Step 200/600, Loss: 0.2314455360174179\n",
      "Epoch 11/20, Step 300/600, Loss: 0.1567559838294983\n",
      "Epoch 11/20, Step 400/600, Loss: 0.23744869232177734\n",
      "Epoch 11/20, Step 500/600, Loss: 0.15491776168346405\n",
      "Epoch 11/20, Step 600/600, Loss: 0.11450475454330444\n",
      "Epoch 12/20, Step 100/600, Loss: 0.26555657386779785\n",
      "Epoch 12/20, Step 200/600, Loss: 0.1202922984957695\n",
      "Epoch 12/20, Step 300/600, Loss: 0.2392200529575348\n",
      "Epoch 12/20, Step 400/600, Loss: 0.23090732097625732\n",
      "Epoch 12/20, Step 500/600, Loss: 0.21480074524879456\n",
      "Epoch 12/20, Step 600/600, Loss: 0.12687771022319794\n",
      "Epoch 13/20, Step 100/600, Loss: 0.15008562803268433\n",
      "Epoch 13/20, Step 200/600, Loss: 0.19456113874912262\n",
      "Epoch 13/20, Step 300/600, Loss: 0.08470037579536438\n",
      "Epoch 13/20, Step 400/600, Loss: 0.3320324718952179\n",
      "Epoch 13/20, Step 500/600, Loss: 0.16789959371089935\n",
      "Epoch 13/20, Step 600/600, Loss: 0.17863185703754425\n",
      "Epoch 14/20, Step 100/600, Loss: 0.04244634136557579\n",
      "Epoch 14/20, Step 200/600, Loss: 0.09049037098884583\n",
      "Epoch 14/20, Step 300/600, Loss: 0.13721168041229248\n",
      "Epoch 14/20, Step 400/600, Loss: 0.22278057038784027\n",
      "Epoch 14/20, Step 500/600, Loss: 0.1809229999780655\n",
      "Epoch 14/20, Step 600/600, Loss: 0.1345299780368805\n",
      "Epoch 15/20, Step 100/600, Loss: 0.07777392119169235\n",
      "Epoch 15/20, Step 200/600, Loss: 0.14806769788265228\n",
      "Epoch 15/20, Step 300/600, Loss: 0.05979067459702492\n",
      "Epoch 15/20, Step 400/600, Loss: 0.22702665627002716\n",
      "Epoch 15/20, Step 500/600, Loss: 0.09908521920442581\n",
      "Epoch 15/20, Step 600/600, Loss: 0.15394264459609985\n",
      "Epoch 16/20, Step 100/600, Loss: 0.11097726225852966\n",
      "Epoch 16/20, Step 200/600, Loss: 0.14240196347236633\n",
      "Epoch 16/20, Step 300/600, Loss: 0.2216857373714447\n",
      "Epoch 16/20, Step 400/600, Loss: 0.11799356341362\n",
      "Epoch 16/20, Step 500/600, Loss: 0.11948749423027039\n",
      "Epoch 16/20, Step 600/600, Loss: 0.21283872425556183\n",
      "Epoch 17/20, Step 100/600, Loss: 0.11596935987472534\n",
      "Epoch 17/20, Step 200/600, Loss: 0.17229898273944855\n",
      "Epoch 17/20, Step 300/600, Loss: 0.10333152115345001\n",
      "Epoch 17/20, Step 400/600, Loss: 0.2047833800315857\n",
      "Epoch 17/20, Step 500/600, Loss: 0.0625755563378334\n",
      "Epoch 17/20, Step 600/600, Loss: 0.12222820520401001\n",
      "Epoch 18/20, Step 100/600, Loss: 0.14631566405296326\n",
      "Epoch 18/20, Step 200/600, Loss: 0.05671324208378792\n",
      "Epoch 18/20, Step 300/600, Loss: 0.27894890308380127\n",
      "Epoch 18/20, Step 400/600, Loss: 0.09785232692956924\n",
      "Epoch 18/20, Step 500/600, Loss: 0.15273481607437134\n",
      "Epoch 18/20, Step 600/600, Loss: 0.10690388083457947\n",
      "Epoch 19/20, Step 100/600, Loss: 0.2101448029279709\n",
      "Epoch 19/20, Step 200/600, Loss: 0.10061411559581757\n",
      "Epoch 19/20, Step 300/600, Loss: 0.13301867246627808\n",
      "Epoch 19/20, Step 400/600, Loss: 0.15228766202926636\n",
      "Epoch 19/20, Step 500/600, Loss: 0.15208400785923004\n",
      "Epoch 19/20, Step 600/600, Loss: 0.0833149328827858\n",
      "Epoch 20/20, Step 100/600, Loss: 0.16185815632343292\n",
      "Epoch 20/20, Step 200/600, Loss: 0.12787696719169617\n",
      "Epoch 20/20, Step 300/600, Loss: 0.097135029733181\n",
      "Epoch 20/20, Step 400/600, Loss: 0.1681729108095169\n",
      "Epoch 20/20, Step 500/600, Loss: 0.08245610445737839\n",
      "Epoch 20/20, Step 600/600, Loss: 0.0697326585650444\n",
      "Accuracy: 97.98%\n"
     ]
    }
   ],
   "source": [
    "train(lp_model, lp_criterion, lp_optimizer, epochs=20, scheduler=lp_scheduler)\n",
    "test(lp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
