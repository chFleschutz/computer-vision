{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Pytorch needs pythont 3.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./../data', train=True, transform=transforms, download=True)\n",
    "test_dataset = datasets.MNIST(root='./../data', train=False, transform=transforms, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_summary(model):\n",
    "    def layer_summary(layer):\n",
    "        output_shape = None\n",
    "        if hasattr(layer, 'out_channels'):\n",
    "            output_shape = (layer.out_channels, \"H_out\", \"W_out\")\n",
    "        elif hasattr(layer, 'out_features'):\n",
    "            output_shape = (layer.out_features)\n",
    "        elif isinstance(layer, torch.nn.modules.pooling._MaxPoolNd):\n",
    "            output_shape = (layer.kernel_size, \"H_out\", \"W_out\")\n",
    "\n",
    "        num_params = sum(p.numel() for p in layer.parameters() if p.requires_grad)\n",
    "        return output_shape, num_params\n",
    "\n",
    "    model_name = model.__class__.__name__\n",
    "    print(f\"'{model_name}' Model Summary:\")\n",
    "\n",
    "    print(\"=\"*75)\n",
    "    print(f\"{'Layer':<30} {'Output Shape':<30} {'Param #':<15}\")\n",
    "    print(\"=\"*75)\n",
    "    \n",
    "    for name, layer in model.named_children():\n",
    "        output_shape, num_params = layer_summary(layer)\n",
    "        print(f\"{name:<30} {str(output_shape):<30} {num_params:<15}\")\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    print(\"=\"*75)\n",
    "    print(f\"Total params:          {total_params}\")\n",
    "    print(f\"Trainable params:      {trainable_params}\")\n",
    "    print(f\"Non-trainable params:  {total_params - trainable_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print(f'Epoch {epoch+1}/{epochs}, Step {i+1}/{len(train_loader)}, Loss: {loss.item()}')\n",
    "\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f'Accuracy: {correct / total * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Classifier\n",
    "\n",
    "from https://gist.github.com/dinhnguyenduc1994/b5881bf922054afb311b0c9a053c0357"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'SoftMax' Model Summary:\n",
      "===========================================================================\n",
      "Layer                          Output Shape                   Param #        \n",
      "===========================================================================\n",
      "linear                         10                             7850           \n",
      "===========================================================================\n",
      "Total params:          7850\n",
      "Trainable params:      7850\n",
      "Non-trainable params:  0\n"
     ]
    }
   ],
   "source": [
    "class SoftMax(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SoftMax, self).__init__()\n",
    "        self.linear = nn.Linear(28 * 28, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        z = self.linear(x)\n",
    "        return z\n",
    "    \n",
    "sl_model = SoftMax().to(device)\n",
    "sl_optimizer = torch.optim.SGD(sl_model.parameters(), lr=0.1)\n",
    "sl_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print_model_summary(sl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Step 100/600, Loss: 0.5822100639343262\n",
      "Epoch 1/2, Step 200/600, Loss: 0.6330122947692871\n",
      "Epoch 1/2, Step 300/600, Loss: 0.3382495641708374\n",
      "Epoch 1/2, Step 400/600, Loss: 0.4639661908149719\n",
      "Epoch 1/2, Step 500/600, Loss: 0.25460952520370483\n",
      "Epoch 1/2, Step 600/600, Loss: 0.6904569864273071\n",
      "Epoch 2/2, Step 100/600, Loss: 0.31767863035202026\n",
      "Epoch 2/2, Step 200/600, Loss: 0.4055829644203186\n",
      "Epoch 2/2, Step 300/600, Loss: 0.32371482253074646\n",
      "Epoch 2/2, Step 400/600, Loss: 0.5221964120864868\n",
      "Epoch 2/2, Step 500/600, Loss: 0.5694730281829834\n",
      "Epoch 2/2, Step 600/600, Loss: 0.37746086716651917\n",
      "Accuracy: 88.69%\n"
     ]
    }
   ],
   "source": [
    "train(sl_model, sl_criterion, sl_optimizer, epochs=2)\n",
    "test(sl_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'SimpleCNN' Model Summary:\n",
      "===========================================================================\n",
      "Layer                          Output Shape                   Param #        \n",
      "===========================================================================\n",
      "conv1                          (32, 'H_out', 'W_out')         320            \n",
      "conv2                          (64, 'H_out', 'W_out')         18496          \n",
      "pool                           (2, 'H_out', 'W_out')          0              \n",
      "fc1                            128                            401536         \n",
      "fc2                            10                             1290           \n",
      "===========================================================================\n",
      "Total params:          421642\n",
      "Trainable params:      421642\n",
      "Non-trainable params:  0\n"
     ]
    }
   ],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "\n",
    "        x = x.view(-1, 64 * 7 * 7) # Flatten the tensor\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "cnn_model = SimpleCNN().to(device)\n",
    "cnn_criterion = nn.CrossEntropyLoss()\n",
    "cnn_optimizer = optim.SGD(cnn_model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "print_model_summary(cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Step 100/600, Loss: 2.196310043334961\n",
      "Epoch 1/2, Step 200/600, Loss: 1.7481510639190674\n",
      "Epoch 1/2, Step 300/600, Loss: 0.8646388053894043\n",
      "Epoch 1/2, Step 400/600, Loss: 0.6793437004089355\n",
      "Epoch 1/2, Step 500/600, Loss: 0.4401340186595917\n",
      "Epoch 1/2, Step 600/600, Loss: 0.44913265109062195\n",
      "Epoch 2/2, Step 100/600, Loss: 0.3419264853000641\n",
      "Epoch 2/2, Step 200/600, Loss: 0.34555405378341675\n",
      "Epoch 2/2, Step 300/600, Loss: 0.36979442834854126\n",
      "Epoch 2/2, Step 400/600, Loss: 0.32078173756599426\n",
      "Epoch 2/2, Step 500/600, Loss: 0.2504320740699768\n",
      "Epoch 2/2, Step 600/600, Loss: 0.1855747401714325\n",
      "Accuracy: 92.16%\n"
     ]
    }
   ],
   "source": [
    "train(cnn_model, cnn_criterion, cnn_optimizer, epochs=2)\n",
    "test(cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
